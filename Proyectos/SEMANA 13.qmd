---
title: "SEMANA 13"
format: html
editor: visual
---

### SEMANA 13

### INTEGRANTES:

-   Apaza Bedia Eva Lucia

-   Cancho Villanueva Fiorella Anallely

-   Inga Salinas Jean Pierre

-   Huaraca Palomino Kriss Syntia

-   Moreno VillaJuan Marjorie Rubi

## Cargar los paquetes

```{r}
install.packages("factoextra")
install.packages("cluster")
```

```{r}
library(factoextra)
library(cluster)
library(here)
library(rio)
library(tidyverse)
```

# 1 ¿Cómo aplicaremos Machine Learning a esta sesión?

Para responder preguntas de investigación en salud hepática, a menudo es necesario recolectar múltiples medidas clínicas y bioquímicas en una misma cohorte de pacientes. Por ejemplo, además de variables sociodemográficas como la edad, el sexo y el tratamiento recibido, se pueden recolectar diversas variables clínicas como presencia de ascitis, hepatomegalia, edema, así como parámetros de laboratorio como bilirrubina, colesterol, cobre sérico, fosfatasa alcalina, transaminasas, triglicéridos, plaquetas y tiempo de protrombina.

Es posible que existan patrones latentes entre estos valores, es decir, que algunas variables estén correlacionadas y definan perfiles biológicos o clínicos distintivos. Por ejemplo, pacientes con descompensación hepática avanzada podrían presentar elevaciones marcadas de bilirrubina y fosfatasa alcalina, junto con hipoalbuminemia y trombocitopenia, mientras que otros pacientes podrían tener un perfil más estable.

## 1.1 Uso de las técnicas de agrupamiento para responden preguntas de investigación en salud

Las técnicas de agrupamiento son métodos exploratorios útiles para clasificar pacientes según su perfil clínico y bioquímico. En nuestro caso, aplicaremos estas técnicas a una muestra de pacientes con cirrosis hepática, con el objetivo de identificar subgrupos de individuos con características similares, basándonos en variables como bilirrubina, albumina, colesterol, cobre, fosfatasa alcalina, plaquetas, y otros parámetros relevantes.

A partir del análisis, podremos formar grupos de pacientes que comparten patrones comunes, por ejemplo: pacientes con cirrosis compensada, descompensada o con signos bioquímicos de progresión hepática. Cada grupo contendrá individuos similares entre sí, pero distintos a los de otros grupos.

Estos subgrupos pueden ser utilizados para generar hipótesis sobre el pronóstico, respuesta a tratamientos (placebo vs. D-penicilamina), o riesgo de desenlaces adversos como fallecimiento o trasplante. Por ejemplo, podríamos comparar la supervivencia o evolución clínica entre los clusters encontrados, ayudando a guiar decisiones clínicas y futuras investigaciones.

# 2 Análisis de agrupamiento herarquico (Hierarchical Clustering)

## 2.1 Sobre el problema para esta sesión

El dataset de esta sesión contiene información de pacientes diagnosticados con cirrosis hepática, quienes han sido seguidos clínicamente a lo largo del tiempo. La base de datos incluye variables clínicas y de laboratorio relevantes para la evaluación del estado hepático, como niveles de bilirrubina, albúmina, colesterol, cobre, fosfatasa alcalina, transaminasas, triglicéridos, plaquetas, entre otros.

El objetivo de este ejercicio es aplicar el método de agrupamiento jerárquico para identificar subgrupos de pacientes que compartan características clínicas y bioquímicas similares. Esto permitirá proponer categorías fenotípicas dentro del espectro de la cirrosis, lo que puede ser útil para generar hipótesis sobre riesgo de mortalidad, necesidad de trasplante o diferencias en la respuesta a tratamientos como la D-penicilamina.

## 2.2 El dataset para esta sesión

Para ilustrar el proceso de análisis, usaremos el dataset llamado cirrosis, el cual contiene información de pacientes con diagnóstico de cirrosis hepática. Este conjunto de datos incluye observaciones con variables de seguimiento como los días de seguimiento (Dias_Seguimiento) y el estado final del paciente (Estado), que puede ser fallecido, censurado o censurado por trasplante. Además, incorpora información sobre el tratamiento recibido (Medicamento), ya sea placebo o D-penicilamina, así como datos demográficos como la edad (en días) y el sexo (hombre o mujer).

El dataset también recoge manifestaciones clínicas como la presencia de ascitis, hepatomegalia, aracnoides (angiomas vasculares) y el grado de edema (ausente, leve o severo), que ayudan a caracterizar la presentación física de la enfermedad. En cuanto a los parámetros bioquímicos y hematológicos, se incluyen valores de bilirrubina, colesterol, albúmina, cobre, fosfatasa alcalina, SGOT (AST), triglicéridos, recuento de plaquetas y tiempo de protrombina. Finalmente, los pacientes están clasificados según una variable ordinal denominada Etapa, que representa la severidad clínica de la cirrosis.

Este conjunto de variables nos permitirá realizar análisis de reducción de dimensionalidad mediante PCA y aplicar técnicas de agrupamiento como el clustering jerárquico o K-means, con el objetivo de identificar patrones latentes y subgrupos clínicamente diferenciados dentro de la población con cirrosis.

### 2.2.1 Importando los datos

```{r}
cirrosis <- import(here("data", "cirrosis.csv"))
```

## 2.3 Preparación de los datos

### 2.3.1 Solo datos numéricos

Para el análisis de agrupamiento jerárquico de esta sesión usaremos únicamente variables numéricas. Si bien es posible utilizar variables categóricas en algunos enfoques, este documento se centrará exclusivamente en datos cuantitativos. Por ello, se eliminarán las variables categóricas como Sexo, Medicamento, Estado, Ascitis, Hepatomegalia, Aracnoides, Edema y Etapa. Asimismo, ID será usado como identificador único para los participantes.

```{r}
cirrosis_1 = cirrosis |>
  select(-Sexo, -Medicamento, -Estado, -Ascitis, -Hepatomegalia,
         -Aracnoides, -Edema, -Etapa) |>
  column_to_rownames("ID")
```

### 2.3.2 La importancia de estandarizar

Adicionalmente, es fundamental estandarizar las variables antes de realizar el análisis de agrupamiento jerárquico. Estandarizar significa transformar las variables a una escala común para hacerlas comparables entre sí. Esto es especialmente importante porque uno de los pasos clave en el método de agrupamiento consiste en calcular distancias entre los objetos (en este caso, los pacientes) a partir de las variables clínicas incluidas en el dataset. Sin embargo, dichas variables se encuentran originalmente medidas en diferentes escalas y unidades.

Por ejemplo, la bilirrubina se mide en miligramos por decilitro (mg/dL), el cobre en microgramos por decilitro (µg/dL), la fosfatasa alcalina en unidades por litro (U/L), y el tiempo de protrombina en segundos. Si no se realiza una estandarización previa, las variables con valores numéricos más grandes o con unidades distintas podrían influir desproporcionadamente en el cálculo de distancias, generando agrupamientos sesgados o poco representativos de la verdadera estructura de los datos.

Para ilustrar este punto: si se agrupa a los pacientes considerando simultáneamente su bilirrubina (mg/dL) y su tiempo de protrombina (segundos), cabe preguntarse: ¿una diferencia de 1 mg/dL en bilirrubina es tan relevante como una diferencia de 1 segundo en el tiempo de protrombina? ¿Qué variable debería tener mayor peso en la formación de los grupos? Sin una estandarización previa, estas diferencias no serían comparables, y las variables con mayor rango numérico dominarán el cálculo de distancias, afectando los resultados de la clasificación. Por ello, es imprescindible aplicar una función de estandarización, como scale() en R, que transforma las variables para que tengan media cero y desviación estándar uno, permitiendo así que todas contribuyan equitativamente al análisis.

```{r}
cirrosis_escalado = scale(cirrosis_1)
```

Un vistazo a los datos antes del escalamiento:

```{r}
head(cirrosis_1)
```

y un vistazo después del escalamiento:

```{r}
head(cirrosis_escalado)
```

Luego del escalamiento, observamos que todas las variables han sido transformadas a una escala comparable. Por ejemplo, en la primera fila, la edad estandarizada es de aproximadamente 0.77 desviaciones estándar por encima de la media, mientras que la bilirrubina es 2.56 desviaciones estándar por encima. En contraste, la albúmina es -2.11 desviaciones por debajo de la media. Este patrón sugiere que el paciente 1 tenía una bilirrubina muy elevada y una albúmina muy baja en comparación con el promedio del resto de la muestra, lo cual podría ser indicativo de disfunción hepática avanzada.

## 2.4 Cálculo de distancias

Dado que uno de los pasos es encontrar "cosas similares", necesitamos definir "similar" en términos de distancia. Esta distancia la calcularemos para cada par posible de objetos (participantes) en nuestro dataset. Por ejemplo, si tuvieramos a los pacientes A, B y C, las distancia se calcularían para A vs B; A vs C; y B vs C. En R, podemos utilizar la función `dist()` para calcular la distancia entre cada par de objetos en un conjunto de datos. El resultado de este cálculo se conoce como matriz de distancias o de disimilitud.

```{r}
dist_cirrosis_data <- dist(cirrosis_escalado, method = "euclidean")
```

## 2.4.1 (opcional) Visualizando las distancias euclidianas con un mapa de calor

Una forma de visualizar si existen patrones de agrupamiento es usando mapas de calor (heatmaps). En R usamos la función `fviz_dist()` del paquete factoextra para crear un mapa de calor.

```{r}
fviz_dist(dist_cirrosis_data)
```

El nivel del color en este gráfico es proporcional al valor de disimilitud entre observaciones (pacientes) en función de sus variables clínicas y bioquímicas estandarizadas. Por ejemplo, un color más rojo indica una distancia pequeña o cercana a 0 entre dos pacientes, lo cual sugiere que tienen perfiles similares. En cambio, los tonos azulados o morados indican mayor distancia, es decir, mayor diferencia entre pacientes.

La línea diagonal que atraviesa el gráfico desde la esquina superior izquierda hasta la inferior derecha representa el cruce de cada observación consigo misma, por lo tanto, siempre tendrá una distancia de cero (color rojo intenso). Las regiones con bloques consecutivos de color homogéneo (más rojizo o más claro) sugieren la presencia de grupos de pacientes que comparten similitudes clínicas o bioquímicas.

## 2.5 El método de agrupamiento: función de enlace (linkage)

El agrupamiento jerárquico es un método que empieza agrupando a los pacientes que presentan perfiles clínicos y bioquímicos más parecidos entre sí, por lo que es fácil de aplicar en las etapas iniciales del análisis. Sin embargo, no basta con calcular las distancias entre todos los pares de pacientes. Una vez que se forma un nuevo grupo (clúster), es necesario definir cómo se medirá la distancia entre ese nuevo grupo y los demás pacientes o grupos ya existentes.

Existen varias formas de hacerlo, y cada una genera un tipo diferente de agrupamiento jerárquico. La función de enlace (linkage) toma la información de distancias obtenida mediante la función `dist()` y agrupa pares de pacientes en clústeres basándose en su similitud. Luego, esos nuevos clústeres se enlazan entre sí de manera sucesiva para formar grupos más grandes. Este proceso continúa hasta que todos los pacientes del conjunto de datos quedan agrupados en un único árbol jerárquico.

Hay distintos métodos para realizar este agrupamiento, entre ellos: Enlace completo (o máximo), Enlace mínimo (o simple), Enlace promedio, Enlace de centroide y el Método de varianza mínima de Ward. No entraremos en detalle sobre las diferencias entre estos métodos, pero para este análisis, el método de Ward resulta adecuado porque tiende a formar clústeres balanceados en tamaño y estructura. Por ello, en este ejemplo, usaremos el método de varianza mínima de Ward.

```{r}
dist_link_cirrosis_data <- hclust(d = dist_cirrosis_data, method = "ward.D2")
```

## 2.7 Dendrogramas para la visualización de patrones

Los dendrogramas es una representación gráfica del árbol jerárquico generado por la función `hclust()`.

```{r}
fviz_dend(dist_link_cirrosis_data, cex = 0.7)
```

El dendrograma obtenido representa la estructura jerárquica de agrupamiento entre los pacientes con cirrosis, en base a sus características clínicas y bioquímicas estandarizadas. En el eje horizontal se encuentran las observaciones (pacientes), y en el eje vertical la altura de fusión o "distancia" entre grupos.

Se observa que las fusiones iniciales (en la parte baja del gráfico) corresponden a pacientes con alta similitud, mientras que las uniones a mayor altura indican la integración de grupos cada vez más disímiles. La forma escalonada del dendrograma sugiere la presencia de subgrupos naturales, especialmente en la parte media del gráfico donde varios clústeres se mantienen separados antes de unirse.

Este resultado respalda la hipótesis de que existen patrones clínicos diferenciados dentro de la población analizada, lo que valida el uso de técnicas de clustering como estrategia exploratoria para clasificar pacientes con características similares. Una siguiente etapa consistiría en definir el número óptimo de grupos y analizarlos clínicamente.

## 2.8 ¿Cúantos grupos se formaron en el dendrograma?

Uno de los desafíos en el uso del agrupamiento jerárquico es que el dendrograma no indica automáticamente cuántos grupos se deben formar ni en qué punto debe cortarse el árbol para definirlos. Esta decisión queda a criterio del investigador, quien debe analizar visualmente la estructura del dendrograma.

En el caso de nuestro análisis, se observa que el dendrograma presenta tres grandes ramas principales que se mantienen separadas antes de fusionarse, lo cual sugiere la existencia de tres clústeres bien diferenciados en la muestra de pacientes con cirrosis.

En el siguiente código se define el argumento k = 3, que indica el número de grupos que se desea representar visualmente. Se agregan colores para facilitar la interpretación y se activa la opción rect = TRUE para delimitar los clústeres:

```{r}
fviz_dend(dist_link_cirrosis_data,
          k = 3,
          cex = 0.5,
          k_colors = c("#2E9FDF", "#E7B800", "#FC4E07"),
          color_labels_by_k = TRUE,
          rect = TRUE)
```

En el gráfico anterior se presenta el dendrograma resultante del análisis de agrupamiento jerárquico aplicado a los pacientes con cirrosis hepática, empleando el método de enlace de varianza mínima de Ward y distancia euclidiana. Con base en la inspección visual del dendrograma, se definió un corte en tres grupos (`k = 3`), representados mediante los colores azul, amarillo y rojo.

El corte a nivel de tres clústeres revela la existencia de tres conglomerados diferenciados de pacientes, los cuales exhiben trayectorias clínicas o bioquímicas similares dentro de cada grupo. El grupo rojo, que representa el conjunto más grande, incluye a la mayoría de pacientes y podría corresponder a un perfil clínico intermedio o más común dentro de la muestra. En contraste, los grupos azul y amarillo contienen pacientes que se fusionan más temprano en el árbol jerárquico, lo que indica mayor homogeneidad interna y potencialmente fenotipos extremos o más definidos

# 3 Agrupamiento con el algoritmo K-Means

El método de agrupamiento (usando el algoritmo) K-means es la técnica de machine learning más utilizado para dividir un conjunto de datos en un número determinado de k grupos (es decir, k clústeres), donde k representa el número de grupos predefinido por el investigador. Esto contrasta con la técnica anterior, dado que aquí sí iniciamos con un grupo pre-definido cuya idoniedad (de los grupos) puede ser evaluado. En detalle, el esta técnica clasifica a los objetos (participantes) del dataset en múltiples grupos, de manera que los objetos dentro de un mismo clúster sean lo más similares posible entre sí (alta similitud intragrupo), mientras que los objetos de diferentes clústeres sean lo más diferentes posible entre ellos (baja similitud intergrupo). En el agrupamiento k-means, cada clúster se representa por su centro (centroide), que corresponde al promedio de los puntos asignados a dicho clúster.

Aquí como funciona el algoritmo de K-Means

1.  Indicar cuántos grupos (clústeres) se quieren formar. Por ejemplo, si se desea dividir a los pacientes en 3 grupos según sus características clínicas, entonces K=3.
2.  Elegir aleatoriamente K casos del conjunto de datos como centros iniciales. Por ejemplo, R selecciona al azar 3 pacientes cuyas características (edad, IMC, creatinina, etc.) servirán como punto de partida para definir los grupos.
3.  Asignar cada paciente al grupo cuyo centro esté más cerca, usando la distancia euclidiana. Es como medir con una regla cuál centroide (paciente promedio) está más próximo a cada paciente en función de todas sus variables.
4.  Calcular un nuevo centro para cada grupo. Es decir, calcular el promedio de todas las variables de los pacientes que quedaron en ese grupo. Por ejemplo, si en el grupo 1 quedaron 40 pacientes, el nuevo centroide será el promedio de la edad, IMC, creatinina, etc., de esos 40 pacientes. Este centroide es un conjunto de valores (uno por cada variable).
5.  Repetir los pasos 3 y 4 hasta que los pacientes dejen de cambiar de grupo o hasta alcanzar un número máximo de repeticiones (en R, por defecto son 10 repeticiones). Esto permitirá que los grupos finales sean estables.

## 3.1 El problema y dataset para este ejercicio

Usaremos el mismo dataset y el mismo problema que el que empleamos en el ejercicio anterior (para Agrupamiento Jerárquico).

## 3.2 Estimando el número óptimo de clusters

Como indiqué arriba, el método de agrupamiento k-means requiere que el usuario especifique el número de clústeres (grupos) a generar. Una pregunta fundamental es: ¿cómo elegir el número adecuado de clústeres esperados (k)?

Aquí muestro una solución sencilla y popular: realizar el agrupamiento k-means probando diferentes valores de k (número de clústeres). Luego, se grafica la suma de cuadrados dentro de los clústeres (WSS) en función del número de clústeres. En R, podemos usar la función fviz_nbclust() para estimar el número óptimo de clústeres.

Primero escalamos los datos:

```{r}
cirrosis_escalado <- na.omit(cirrosis_escalado)
```

```{r}
hemo_cirrosis_escalado = scale(cirrosis_1)
```

Ahora graficamos la suma de cuadrados dentro de los gráficos

```{r}
fviz_nbclust(cirrosis_escalado, kmeans, nstart = 25, method = "wss") + 
  geom_vline(xintercept = 3, linetype = 2)
```

La gráfica anterior representa la suma total de cuadrados dentro de los grupos (WSS) en función del número de clústeres (k) utilizados en un análisis de K-means, aplicado sobre los datos estandarizados de pacientes con cirrosis. Este enfoque permite estimar el número óptimo de grupos al observar el punto donde se produce una disminución pronunciada en la variabilidad intra-clúster.

En el gráfico se observa una caída abrupta en la WSS entre k = 1 y k = 3, seguida de una pendiente más suave a partir de k = 4 en adelante. Este patrón indica que el mayor beneficio en la reducción de la varianza dentro de los grupos ocurre al pasar de 1 a 3 clústeres. A partir de k = 3, agregar más grupos sigue reduciendo la WSS pero con ganancias marginales decrecientes.

## 3.3 Cálculo del agrupamiento k-means

Dado que el resultado final del agrupamiento k-means es sensible a las asignaciones aleatorias iniciales, se especifica el argumento `nstart = 25`. Esto significa que R intentará 25 asignaciones aleatorias diferentes y seleccionará la mejor solución, es decir, aquella con la menor variación dentro de los clústeres. El valor predeterminado de `nstart` en R es 1. Sin embargo, se recomienda ampliamente utilizar un valor alto, como 25 o 50, para obtener un resultado más estable y confiable. El valor empleado aquí, fue usado para determinar el número de clústeres óptimos.

```{r}
set.seed(123)
km_res <- kmeans(cirrosis_escalado, 3, nstart = 25)
```

```{r}
km_res
```

El resultado del análisis de K-means con tres clústeres muestra dos elementos clave:

Las medias o centros de los clústeres (Cluster means): Se presentan en una matriz donde cada fila corresponde a un grupo (1, 2 o 3) y cada columna a una variable clínica o bioquímica. Estos valores reflejan el perfil promedio de cada grupo. Por ejemplo, el clúster 3 muestra valores más altos en bilirrubina, fosfatasa alcalina y triglicéridos, lo que podría indicar un fenotipo de mayor descompensación hepática.

Un vector de asignación de clúster (Clustering vector): Es una secuencia de números enteros (de 1 a 3) que indica a qué grupo ha sido asignado cada paciente del dataset. Esto permite analizar la distribución de los individuos y comparar características entre grupos en etapas posteriores.

## 3.4 Visualización de los clústeres k-means

Al igual que en el análisis jerárquico anterior, los datos pueden representarse en un gráfico de dispersión, coloreando cada paciente según el clúster al que pertenece. Sin embargo, como los datos de cirrosis contienen múltiples variables clínicas y bioquímicas, surge el problema de decidir cuáles usar en los ejes del gráfico.

Una solución común es aplicar una técnica de reducción de dimensiones, como el Análisis de Componentes Principales (PCA). El PCA transforma las variables originales (ya estandarizadas) en dos nuevas dimensiones que maximizan la variabilidad explicada, permitiendo representar los datos de forma más clara y visual.

La función fviz_cluster() del paquete factoextra permite visualizar los clústeres generados por k-means en el plano de las dos primeras componentes principales. Esta función toma como argumentos el resultado del modelo (km_res) y la matriz de datos original estandarizada (cirrosis_escalado).

```{r}
fviz_cluster(
  km_res,
  data = cirrosis_escalado,
  palette = c("#2E9FDF", "#E7B800", "#FC4E07"),
  ellipse.type = "euclid",
  repel = TRUE,
  ggtheme = theme_minimal()
)
```

El gráfico anterior representa la distribución de los pacientes con cirrosis en el plano de las dos primeras componentes principales, derivadas del Análisis de Componentes Principales (PCA). Este plano captura un total de 42.2% de la variabilidad total de los datos (Dim1 = 26.3%, Dim2 = 15.9%).

Cada punto corresponde a un paciente, y su color indica el clúster asignado por el algoritmo k-means:

Clúster 1 (azul): Es el grupo más numeroso y se concentra principalmente en la parte derecha del gráfico, con pacientes más homogéneos. Podría corresponder a un perfil clínico menos complejo o más estable.

Clúster 2 (amarillo): Se ubica en la zona inferior izquierda, claramente separado del clúster 1. Sus pacientes comparten características intermedias y forman un grupo compacto, lo que sugiere coherencia interna.

Clúster 3 (rojo): Ocupa la parte superior izquierda y muestra mayor dispersión, lo que podría reflejar mayor heterogeneidad clínica o casos extremos en algunas variables (como bilirrubina o triglicéridos elevadas).

Las elipses de dispersión muestran la cobertura aproximada de cada grupo bajo el supuesto de distribución euclidiana, lo que permite observar que los tres clústeres están razonablemente bien separados en el espacio proyectado.

En conjunto, el gráfico evidencia que la segmentación de pacientes en tres grupos ofrece una clasificación visualmente consistente, con patrones que podrían reflejar diferencias clínicas relevantes a estudiar en mayor profundidad.
